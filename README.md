# mymodel1


## 概要 / Overview

本リポジトリは、**ニューラルネットワークやバックプロパゲーションに依存しない**文字認識の実験的実装である。
GPUや大規模行列演算を前提とせず、**CPUのみ**で動作する軽量な構造設計型モデルにより、MNIST に対して **96.36%** の精度を達成している。

本手法は、画像を連続値テンソルとして扱うのではなく、
**格子点上の離散的な点集合（散布図）**として捉え、
幾何・論理・構造的特徴を人手で構成することを特徴とする。

---

## What this is NOT

本実装は以下を**使用しない**：

* ニューラルネットワーク（CNN / ViT 等）
* バックプロパゲーション
* GPU / CUDA
* 大規模な行列積（BLAS 前提の数値線形代数）
* 浮動小数点最適化に依存した学習

「学習にすべてを丸投げする」アプローチではなく、
**表現は設計し、判断のみを軽量に学習する**という立場を取る。

---

## Core Idea

### 1. 離散表現としての文字

入力画像はピクセル配列ではなく、

* 二値マスク
* エッジ / コア領域
* 格子点上の点集合

として扱われる。
文字は「画像」ではなく、**構造を持った離散オブジェクト**として解釈される。

---

### 2. 幾何モーメントと回転構造

特徴量の一部には、二次形式に基づく幾何モーメントを用いる。

例として
[
x^2 + xy + y^2 = 1
]
のような回転楕円（二次形式）の発想をヒントに、
軸に依存しにくい形状情報を低次元で要約している。

これは、データ拡張によって回転耐性を「学習させる」のではなく、
**幾何的に最初から潰す**設計である。

---

### 3. 構造・トポロジー特徴

文字の構造を捉えるため、

* 接続成分数
* 遷移数
* 近傍関係
* 局所的なトポロジー

といった、**形のつながり**に関する特徴を導入している。

---

### 4. 論理演算中心の計算

内部計算の中心は以下で構成される：

* ビット演算（XOR / AND）
* popcount・カウント
* スカラー更新（重みの加減算）
* 配列の走査・累積

これらは数値線形代数としての「行列計算」ではなく、
**離散的・論理的な処理**である。

---

### 5. 軽量な学習

分類には軽量なパーセプトロンを用いるが、

* 勾配計算なし
* 行列積前提なし
* 低次元・整数中心

という制約下で行われる。
学習の役割は「境界の微調整」に限定されている。

---

## Why CPU-only?

本実装は意図的に **CPUのみ** を前提としている。

これは性能制限ではなく、

* 再現性（誰でも手元で動かせる）
* 設計の説明可能性
* 組み込み・省電力への適性
* GPUがなくても成立する認識原理の検証

を目的とした設計上の選択である。

---

## Results

* Dataset: MNIST
* Accuracy: **96.36%**
* Hardware: CPU only
* GPU / CUDA: not used



---

## Positioning

本手法は、

* 深層学習の代替
* 既存OCRの改良

を直接目指すものではない。



